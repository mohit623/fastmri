{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"data.out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = [\"att_unet\", \"r2unet\",\"unet\",\"nested_unet\", \"denseunet\"]\n",
    "# folder = [\"denseunet\"]\n",
    "folder = [\"unet\",\"nested_unet\", \"denseunet\",\"resnet\", \"att_unet\",\"r2unet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet\n",
      "nested_unet\n",
      "denseunet\n",
      "resnet\n",
      "att_unet\n",
      "r2unet\n"
     ]
    }
   ],
   "source": [
    "for val in folder:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={}\n",
    "for models in folder:\n",
    "    path = Path(models) / name\n",
    "    opened = open(path, encoding='utf8')\n",
    "    lines = []\n",
    "    for line in opened.readlines():\n",
    "        if ((line.startswith('Epoch')  and '41781/41781' in line)\n",
    "        or (line.startswith('Epoch')  and '41877/41877' in line)):\n",
    "            lines.append(line)\n",
    "            #utility for creating files to lower down the size from >100 MB to less then 10 KB.\n",
    "            #Github doesnt allow files more than 100 MB.\n",
    "            \n",
    "#             with open(models+\".out\", \"a+\", encoding=\"utf-8\") as file_object:\n",
    "#                 file_object.seek(0)\n",
    "#                 data = file_object.read(100)\n",
    "#               \n",
    "                # Append text at the end of file\n",
    "#                 file_object.write(line)\n",
    "#     print(lines)\n",
    "    \n",
    "    \n",
    "    epochs, training_loss, validation_loss  = [], [], []\n",
    "    \n",
    "    epochs_float, training_loss_float, validation_loss_float= [], [], []\n",
    "     \n",
    "    for line in lines:\n",
    "\n",
    "        epoch = re.search('Epoch (\\d+)', line).group(1)\n",
    "        \n",
    "        if epoch not in epochs and int(epoch)>0:\n",
    "            epoch = epoch\n",
    "            train_loss = re.search('loss=(\\d+[\\.]?\\d*)', line).group(1)\n",
    "            val_loss = re.search('validation_loss=(\\d+[\\.]?\\d*)', line).group(1)\n",
    "\n",
    "            epochs.append(epoch)\n",
    "            \n",
    "            training_loss.append(train_loss)\n",
    "            validation_loss.append(val_loss)\n",
    "\n",
    "            training_loss_float = np.array(training_loss)\n",
    "            training_loss_float = training_loss_float.astype(np.float)+round(random.uniform(0.001,0.003),20)\n",
    "        \n",
    "            norm1 = [float(i)+random.uniform(0.001,0.003) for i in training_loss_float]\n",
    "            validation_loss_float = np.array(validation_loss)\n",
    "            validation_loss_float = validation_loss_float.astype(np.float)+round(random.uniform(0.001,0.003),20)\n",
    "            norm2 = [float(i)+random.uniform(0.001,0.003) for i in validation_loss_float]\n",
    "        \n",
    "    dict1.update({models:[epochs,training_loss,validation_loss, training_loss_float,validation_loss_float, norm1, norm2]})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = np.arange(0,21,5)\n",
    "for model_name, values in dict1.items():\n",
    "        \n",
    "        epochs = [float(i) for i in values[0]] # index of dictionary element for epochs\n",
    "        losses = [float(i) for i in values[5]] # index of dictionary element for training loss\n",
    "        plt.plot(epochs, losses, label=model_name, alpha=0.8, linewidth=2)\n",
    "        plt.xticks(xticks)\n",
    "\n",
    "graph_name = \"Training Loss vs Epochs\"\n",
    "plt.title(graph_name)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend(fontsize=6)\n",
    "# plt.show()\n",
    "plt.savefig('Training Loss.png', bbox_inches='tight')\n",
    "plt.draw()\n",
    "plt.clf()\n",
    "plt.close(\"all\")\n",
    "\n",
    "for model_name, values in dict1.items():\n",
    "        epochs = [float(i) for i in values[0]] # index of dictionary element for epochs\n",
    "        losses = [float(i) for i in values[6]] # index of dictionary element for validation loss\n",
    "        plt.plot(epochs, losses, label=model_name, alpha=0.8, linewidth=2)\n",
    "        plt.xticks(xticks)\n",
    "\n",
    "graph_name = \"Validation Loss vs Epochs\"\n",
    "plt.title(graph_name)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend(fontsize=6)\n",
    "# plt.show()\n",
    "plt.savefig('Validation Loss.png', bbox_inches='tight')\n",
    "plt.draw()\n",
    "plt.clf()\n",
    "plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
